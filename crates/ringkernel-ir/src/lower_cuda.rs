//! IR to CUDA lowering pass.
//!
//! Lowers IR to CUDA C code for compilation with nvcc.

use std::collections::HashMap;
use std::fmt::Write;

use crate::{
    nodes::*, BackendCapabilities, BlockId, Dimension, IrModule, IrNode, IrType, ScalarType,
    Terminator, ValueId,
};

/// CUDA lowering configuration.
#[derive(Debug, Clone)]
pub struct CudaLoweringConfig {
    /// Target compute capability (e.g., 80 for SM 8.0).
    pub compute_capability: u32,
    /// Enable cooperative groups.
    pub cooperative_groups: bool,
    /// Enable HLC (Hybrid Logical Clocks).
    pub enable_hlc: bool,
    /// Enable K2K messaging.
    pub enable_k2k: bool,
    /// Use fast math.
    pub fast_math: bool,
    /// Generate debug info.
    pub debug: bool,
}

impl Default for CudaLoweringConfig {
    fn default() -> Self {
        Self {
            compute_capability: 70,
            cooperative_groups: false,
            enable_hlc: false,
            enable_k2k: false,
            fast_math: false,
            debug: false,
        }
    }
}

impl CudaLoweringConfig {
    /// Create config for SM 8.0+.
    pub fn sm80() -> Self {
        Self {
            compute_capability: 80,
            cooperative_groups: true,
            ..Default::default()
        }
    }

    /// Enable persistent kernel features.
    pub fn with_persistent(mut self) -> Self {
        self.enable_hlc = true;
        self.enable_k2k = true;
        self.cooperative_groups = true;
        self
    }
}

/// CUDA code generator.
pub struct CudaLowering {
    config: CudaLoweringConfig,
    output: String,
    indent: usize,
    value_names: HashMap<ValueId, String>,
    name_counter: usize,
    block_labels: HashMap<BlockId, String>,
}

impl CudaLowering {
    /// Create a new CUDA lowering pass.
    pub fn new(config: CudaLoweringConfig) -> Self {
        Self {
            config,
            output: String::new(),
            indent: 0,
            value_names: HashMap::new(),
            name_counter: 0,
            block_labels: HashMap::new(),
        }
    }

    /// Lower an IR module to CUDA code.
    pub fn lower(mut self, module: &IrModule) -> Result<String, LoweringError> {
        // Check capabilities
        self.check_capabilities(module)?;

        // Generate includes
        self.emit_includes();

        // Generate type definitions
        self.emit_type_definitions(module);

        // Generate kernel
        self.emit_kernel(module)?;

        Ok(self.output)
    }

    fn check_capabilities(&self, module: &IrModule) -> Result<(), LoweringError> {
        let cuda_caps = BackendCapabilities::cuda_sm80();

        let unsupported = cuda_caps.unsupported(&module.required_capabilities);
        if !unsupported.is_empty() {
            return Err(LoweringError::UnsupportedCapability(
                unsupported
                    .iter()
                    .map(|c| format!("{}", c))
                    .collect::<Vec<_>>()
                    .join(", "),
            ));
        }

        Ok(())
    }

    fn emit_includes(&mut self) {
        self.emit_line("// Generated by ringkernel-ir CUDA lowering");
        self.emit_line("#include <cuda_runtime.h>");
        self.emit_line("#include <stdint.h>");

        if self.config.cooperative_groups {
            self.emit_line("#include <cooperative_groups.h>");
            self.emit_line("namespace cg = cooperative_groups;");
        }

        self.emit_line("");
    }

    fn emit_type_definitions(&mut self, _module: &IrModule) {
        // HLC timestamp type
        if self.config.enable_hlc {
            self.emit_line("// HLC Timestamp");
            self.emit_line("struct HlcTimestamp {");
            self.indent += 1;
            self.emit_line("uint64_t physical;");
            self.emit_line("uint64_t logical;");
            self.emit_line("uint64_t node_id;");
            self.indent -= 1;
            self.emit_line("};");
            self.emit_line("");
        }

        // Control block for persistent kernels
        if self.config.enable_k2k {
            self.emit_line("// Control Block");
            self.emit_line("struct ControlBlock {");
            self.indent += 1;
            self.emit_line("uint32_t is_active;");
            self.emit_line("uint32_t should_terminate;");
            self.emit_line("uint32_t has_terminated;");
            self.emit_line("uint32_t _pad1;");
            self.emit_line("uint64_t messages_processed;");
            self.emit_line("uint64_t messages_in_flight;");
            self.emit_line("uint64_t input_head;");
            self.emit_line("uint64_t input_tail;");
            self.emit_line("uint64_t output_head;");
            self.emit_line("uint64_t output_tail;");
            self.emit_line("uint32_t input_capacity;");
            self.emit_line("uint32_t output_capacity;");
            self.emit_line("uint32_t input_mask;");
            self.emit_line("uint32_t output_mask;");
            self.indent -= 1;
            self.emit_line("};");
            self.emit_line("");

            // K2H/H2K queue intrinsic declarations
            self.emit_line("// Queue Intrinsics (provided by runtime)");
            self.emit_line("__device__ bool __ringkernel_k2h_enqueue(const void* msg);");
            self.emit_line("__device__ void* __ringkernel_h2k_dequeue();");
            self.emit_line("__device__ bool __ringkernel_h2k_is_empty();");
            self.emit_line("");

            // K2K messaging intrinsic declarations
            self.emit_line("// K2K Messaging Intrinsics (provided by runtime)");
            self.emit_line("__device__ bool __ringkernel_k2k_send(uint64_t target_id, const void* msg);");
            self.emit_line("__device__ void* __ringkernel_k2k_recv();");
            self.emit_line("struct K2KOptionalMsg { bool valid; void* data; };");
            self.emit_line("__device__ K2KOptionalMsg __ringkernel_k2k_try_recv();");
            self.emit_line("");
        }

        // HLC intrinsic declarations
        if self.config.enable_hlc {
            self.emit_line("// HLC Intrinsics (provided by runtime)");
            self.emit_line("__device__ uint64_t __ringkernel_hlc_now();");
            self.emit_line("__device__ uint64_t __ringkernel_hlc_tick();");
            self.emit_line("__device__ uint64_t __ringkernel_hlc_update(uint64_t incoming);");
            self.emit_line("");
        }
    }

    fn emit_kernel(&mut self, module: &IrModule) -> Result<(), LoweringError> {
        // Assign names to values and blocks
        self.assign_names(module);

        // Kernel signature
        let kernel_attr = if self.config.cooperative_groups {
            "__global__ void __launch_bounds__(256)"
        } else {
            "__global__ void"
        };

        write!(self.output, "{} {}(", kernel_attr, module.name).unwrap();

        // Parameters
        for (i, param) in module.parameters.iter().enumerate() {
            if i > 0 {
                write!(self.output, ", ").unwrap();
            }
            let ty = self.lower_type(&param.ty);
            write!(self.output, "{} {}", ty, param.name).unwrap();
        }

        self.emit_line(") {");
        self.indent += 1;

        // Cooperative groups setup
        if self.config.cooperative_groups {
            self.emit_line("cg::grid_group grid = cg::this_grid();");
            self.emit_line("cg::thread_block block = cg::this_thread_block();");
            self.emit_line("");
        }

        // Emit blocks
        self.emit_block(module, module.entry_block)?;

        // Emit other blocks
        for block_id in module.blocks.keys() {
            if *block_id != module.entry_block {
                self.emit_block(module, *block_id)?;
            }
        }

        self.indent -= 1;
        self.emit_line("}");

        Ok(())
    }

    fn assign_names(&mut self, module: &IrModule) {
        // Assign names to parameters
        for param in &module.parameters {
            self.value_names.insert(param.value_id, param.name.clone());
        }

        // Assign names to blocks
        for (block_id, block) in &module.blocks {
            self.block_labels.insert(*block_id, block.label.clone());
        }
    }

    fn emit_block(&mut self, module: &IrModule, block_id: BlockId) -> Result<(), LoweringError> {
        let block = module
            .blocks
            .get(&block_id)
            .ok_or(LoweringError::UndefinedBlock(block_id))?;

        // Block label (skip for entry)
        if block_id != module.entry_block {
            self.emit_line(&format!("{}: {{", block.label));
            self.indent += 1;
        }

        // Instructions
        for inst in &block.instructions {
            self.emit_instruction(module, &inst.result, &inst.result_type, &inst.node)?;
        }

        // Terminator
        if let Some(term) = &block.terminator {
            self.emit_terminator(term)?;
        }

        if block_id != module.entry_block {
            self.indent -= 1;
            self.emit_line("}");
        }

        Ok(())
    }

    fn emit_instruction(
        &mut self,
        _module: &IrModule,
        result: &ValueId,
        result_type: &IrType,
        node: &IrNode,
    ) -> Result<(), LoweringError> {
        let result_name = self.get_or_create_name(*result);
        let ty = self.lower_type(result_type);

        match node {
            // Constants
            IrNode::Constant(c) => {
                let val = self.lower_constant(c);
                self.emit_line(&format!("{} {} = {};", ty, result_name, val));
            }

            // Binary operations
            IrNode::BinaryOp(op, lhs, rhs) => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                let expr = self.lower_binary_op(op, &lhs_name, &rhs_name);
                self.emit_line(&format!("{} {} = {};", ty, result_name, expr));
            }

            // Unary operations
            IrNode::UnaryOp(op, val) => {
                let val_name = self.get_value_name(*val);
                let expr = self.lower_unary_op(op, &val_name);
                self.emit_line(&format!("{} {} = {};", ty, result_name, expr));
            }

            // Comparisons
            IrNode::Compare(op, lhs, rhs) => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                let cmp_op = self.lower_compare_op(op);
                self.emit_line(&format!(
                    "bool {} = {} {} {};",
                    result_name, lhs_name, cmp_op, rhs_name
                ));
            }

            // Memory operations
            IrNode::Load(ptr) => {
                let ptr_name = self.get_value_name(*ptr);
                self.emit_line(&format!("{} {} = *{};", ty, result_name, ptr_name));
            }

            IrNode::Store(ptr, val) => {
                let ptr_name = self.get_value_name(*ptr);
                let val_name = self.get_value_name(*val);
                self.emit_line(&format!("*{} = {};", ptr_name, val_name));
            }

            IrNode::GetElementPtr(ptr, indices) => {
                let ptr_name = self.get_value_name(*ptr);
                let idx_name = self.get_value_name(indices[0]);
                self.emit_line(&format!(
                    "{} {} = &{}[{}];",
                    ty, result_name, ptr_name, idx_name
                ));
            }

            IrNode::SharedAlloc(elem_ty, count) => {
                let elem = self.lower_type(elem_ty);
                self.emit_line(&format!("__shared__ {} {}[{}];", elem, result_name, count));
            }

            // GPU indexing
            IrNode::ThreadId(dim) => {
                let idx = self.lower_dimension(dim, "threadIdx");
                self.emit_line(&format!("{} {} = {};", ty, result_name, idx));
            }

            IrNode::BlockId(dim) => {
                let idx = self.lower_dimension(dim, "blockIdx");
                self.emit_line(&format!("{} {} = {};", ty, result_name, idx));
            }

            IrNode::BlockDim(dim) => {
                let idx = self.lower_dimension(dim, "blockDim");
                self.emit_line(&format!("{} {} = {};", ty, result_name, idx));
            }

            IrNode::GridDim(dim) => {
                let idx = self.lower_dimension(dim, "gridDim");
                self.emit_line(&format!("{} {} = {};", ty, result_name, idx));
            }

            IrNode::GlobalThreadId(dim) => {
                let block_idx = self.lower_dimension(dim, "blockIdx");
                let block_dim = self.lower_dimension(dim, "blockDim");
                let thread_idx = self.lower_dimension(dim, "threadIdx");
                self.emit_line(&format!(
                    "{} {} = {} * {} + {};",
                    ty, result_name, block_idx, block_dim, thread_idx
                ));
            }

            IrNode::WarpId => {
                self.emit_line(&format!("{} {} = threadIdx.x / 32;", ty, result_name));
            }

            IrNode::LaneId => {
                self.emit_line(&format!("{} {} = threadIdx.x % 32;", ty, result_name));
            }

            // Synchronization
            IrNode::Barrier => {
                self.emit_line("__syncthreads();");
            }

            IrNode::MemoryFence(scope) => {
                let fence = match scope {
                    MemoryScope::Thread => "__threadfence_block()",
                    MemoryScope::Threadgroup => "__threadfence_block()",
                    MemoryScope::Device => "__threadfence()",
                    MemoryScope::System => "__threadfence_system()",
                };
                self.emit_line(&format!("{};", fence));
            }

            IrNode::GridSync => {
                if self.config.cooperative_groups {
                    self.emit_line("grid.sync();");
                } else {
                    return Err(LoweringError::RequiresCooperativeGroups);
                }
            }

            // Atomics
            IrNode::Atomic(op, ptr, val) => {
                let ptr_name = self.get_value_name(*ptr);
                let val_name = self.get_value_name(*val);
                let atomic_fn = match op {
                    AtomicOp::Add => "atomicAdd",
                    AtomicOp::Sub => "atomicSub",
                    AtomicOp::Exchange => "atomicExch",
                    AtomicOp::Min => "atomicMin",
                    AtomicOp::Max => "atomicMax",
                    AtomicOp::And => "atomicAnd",
                    AtomicOp::Or => "atomicOr",
                    AtomicOp::Xor => "atomicXor",
                    AtomicOp::Load => {
                        self.emit_line(&format!(
                            "{} {} = atomicAdd({}, 0);",
                            ty, result_name, ptr_name
                        ));
                        return Ok(());
                    }
                    AtomicOp::Store => {
                        self.emit_line(&format!("atomicExch({}, {});", ptr_name, val_name));
                        return Ok(());
                    }
                };
                self.emit_line(&format!(
                    "{} {} = {}({}, {});",
                    ty, result_name, atomic_fn, ptr_name, val_name
                ));
            }

            IrNode::AtomicCas(ptr, expected, desired) => {
                let ptr_name = self.get_value_name(*ptr);
                let exp_name = self.get_value_name(*expected);
                let des_name = self.get_value_name(*desired);
                self.emit_line(&format!(
                    "{} {} = atomicCAS({}, {}, {});",
                    ty, result_name, ptr_name, exp_name, des_name
                ));
            }

            // Warp operations
            IrNode::WarpVote(op, val) => {
                let val_name = self.get_value_name(*val);
                let vote_fn = match op {
                    WarpVoteOp::All => "__all_sync(0xFFFFFFFF, ",
                    WarpVoteOp::Any => "__any_sync(0xFFFFFFFF, ",
                    WarpVoteOp::Ballot => "__ballot_sync(0xFFFFFFFF, ",
                };
                self.emit_line(&format!(
                    "{} {} = {}{})",
                    ty, result_name, vote_fn, val_name
                ));
            }

            IrNode::WarpShuffle(op, val, lane) => {
                let val_name = self.get_value_name(*val);
                let lane_name = self.get_value_name(*lane);
                let shfl_fn = match op {
                    WarpShuffleOp::Index => "__shfl_sync(0xFFFFFFFF, ",
                    WarpShuffleOp::Up => "__shfl_up_sync(0xFFFFFFFF, ",
                    WarpShuffleOp::Down => "__shfl_down_sync(0xFFFFFFFF, ",
                    WarpShuffleOp::Xor => "__shfl_xor_sync(0xFFFFFFFF, ",
                };
                self.emit_line(&format!(
                    "{} {} = {}{}, {})",
                    ty, result_name, shfl_fn, val_name, lane_name
                ));
            }

            // Select
            IrNode::Select(cond, then_val, else_val) => {
                let cond_name = self.get_value_name(*cond);
                let then_name = self.get_value_name(*then_val);
                let else_name = self.get_value_name(*else_val);
                self.emit_line(&format!(
                    "{} {} = {} ? {} : {};",
                    ty, result_name, cond_name, then_name, else_name
                ));
            }

            // Math functions
            IrNode::Math(op, args) => {
                let fn_name = self.lower_math_op(op);
                let args_str: Vec<String> = args.iter().map(|a| self.get_value_name(*a)).collect();
                self.emit_line(&format!(
                    "{} {} = {}({});",
                    ty,
                    result_name,
                    fn_name,
                    args_str.join(", ")
                ));
            }

            // Skip nodes that don't produce CUDA output
            IrNode::Parameter(_) | IrNode::Undef | IrNode::Phi(_) => {}

            // ========================================================================
            // Messaging Operations
            // ========================================================================

            // K2H (Kernel-to-Host) enqueue
            IrNode::K2HEnqueue(value) => {
                let val_name = self.get_value_name(*value);
                // Enqueue returns success status (bool)
                self.emit_line(&format!(
                    "{} {} = __ringkernel_k2h_enqueue({});",
                    ty, result_name, val_name
                ));
            }

            // H2K (Host-to-Kernel) dequeue
            IrNode::H2KDequeue => {
                // Dequeue returns the message struct
                self.emit_line(&format!(
                    "{} {} = __ringkernel_h2k_dequeue();",
                    ty, result_name
                ));
            }

            // H2K queue empty check
            IrNode::H2KIsEmpty => {
                // Returns true if queue is empty
                self.emit_line(&format!(
                    "{} {} = __ringkernel_h2k_is_empty();",
                    ty, result_name
                ));
            }

            // K2K (Kernel-to-Kernel) send
            IrNode::K2KSend(target_id, message) => {
                let target_name = self.get_value_name(*target_id);
                let msg_name = self.get_value_name(*message);
                // Send returns success status (bool)
                self.emit_line(&format!(
                    "{} {} = __ringkernel_k2k_send({}, {});",
                    ty, result_name, target_name, msg_name
                ));
            }

            // K2K blocking receive
            IrNode::K2KRecv => {
                // Blocking receive returns the message struct
                self.emit_line(&format!(
                    "{} {} = __ringkernel_k2k_recv();",
                    ty, result_name
                ));
            }

            // K2K non-blocking try receive
            IrNode::K2KTryRecv => {
                // Try receive returns optional message (use .valid field to check)
                self.emit_line(&format!(
                    "{} {} = __ringkernel_k2k_try_recv();",
                    ty, result_name
                ));
            }

            // ========================================================================
            // HLC (Hybrid Logical Clock) Operations
            // ========================================================================

            // Get current HLC time
            IrNode::HlcNow => {
                // Returns current HLC timestamp (u64)
                self.emit_line(&format!(
                    "{} {} = __ringkernel_hlc_now();",
                    ty, result_name
                ));
            }

            // Tick HLC and return new time
            IrNode::HlcTick => {
                // Increments logical counter and returns new timestamp
                self.emit_line(&format!(
                    "{} {} = __ringkernel_hlc_tick();",
                    ty, result_name
                ));
            }

            // Update HLC from incoming timestamp
            IrNode::HlcUpdate(incoming) => {
                let incoming_name = self.get_value_name(*incoming);
                // Updates HLC using max(local, incoming) + 1 rule
                self.emit_line(&format!(
                    "{} {} = __ringkernel_hlc_update({});",
                    ty, result_name, incoming_name
                ));
            }

            _ => {
                self.emit_line(&format!("// Unhandled: {:?}", node));
            }
        }

        Ok(())
    }

    fn emit_terminator(&mut self, term: &Terminator) -> Result<(), LoweringError> {
        match term {
            Terminator::Return(None) => {
                self.emit_line("return;");
            }
            Terminator::Return(Some(val)) => {
                let val_name = self.get_value_name(*val);
                self.emit_line(&format!("return {};", val_name));
            }
            Terminator::Branch(target) => {
                let label = self.block_labels.get(target).cloned().unwrap_or_default();
                self.emit_line(&format!("goto {};", label));
            }
            Terminator::CondBranch(cond, then_block, else_block) => {
                let cond_name = self.get_value_name(*cond);
                let then_label = self
                    .block_labels
                    .get(then_block)
                    .cloned()
                    .unwrap_or_default();
                let else_label = self
                    .block_labels
                    .get(else_block)
                    .cloned()
                    .unwrap_or_default();
                self.emit_line(&format!(
                    "if ({}) goto {}; else goto {};",
                    cond_name, then_label, else_label
                ));
            }
            Terminator::Switch(val, default, cases) => {
                let val_name = self.get_value_name(*val);
                self.emit_line(&format!("switch ({}) {{", val_name));
                self.indent += 1;
                for (case_val, target) in cases {
                    let case_str = self.lower_constant(case_val);
                    let label = self.block_labels.get(target).cloned().unwrap_or_default();
                    self.emit_line(&format!("case {}: goto {};", case_str, label));
                }
                let default_label = self.block_labels.get(default).cloned().unwrap_or_default();
                self.emit_line(&format!("default: goto {};", default_label));
                self.indent -= 1;
                self.emit_line("}");
            }
            Terminator::Unreachable => {
                self.emit_line("__builtin_unreachable();");
            }
        }
        Ok(())
    }

    fn lower_type(&self, ty: &IrType) -> String {
        match ty {
            IrType::Void => "void".to_string(),
            IrType::Scalar(s) => self.lower_scalar_type(s),
            IrType::Vector(v) => format!("{}{}", self.lower_scalar_type(&v.element), v.count),
            IrType::Ptr(inner) => format!("{}*", self.lower_type(inner)),
            IrType::Array(inner, size) => format!("{}[{}]", self.lower_type(inner), size),
            IrType::Slice(inner) => format!("{}*", self.lower_type(inner)),
            IrType::Struct(s) => s.name.clone(),
            IrType::Function(_) => "void*".to_string(), // Function pointers
        }
    }

    fn lower_scalar_type(&self, ty: &ScalarType) -> String {
        match ty {
            ScalarType::Bool => "bool",
            ScalarType::I8 => "int8_t",
            ScalarType::I16 => "int16_t",
            ScalarType::I32 => "int32_t",
            ScalarType::I64 => "int64_t",
            ScalarType::U8 => "uint8_t",
            ScalarType::U16 => "uint16_t",
            ScalarType::U32 => "uint32_t",
            ScalarType::U64 => "uint64_t",
            ScalarType::F16 => "__half",
            ScalarType::F32 => "float",
            ScalarType::F64 => "double",
        }
        .to_string()
    }

    fn lower_constant(&self, c: &ConstantValue) -> String {
        match c {
            ConstantValue::Bool(b) => if *b { "true" } else { "false" }.to_string(),
            ConstantValue::I32(v) => format!("{}", v),
            ConstantValue::I64(v) => format!("{}LL", v),
            ConstantValue::U32(v) => format!("{}u", v),
            ConstantValue::U64(v) => format!("{}ull", v),
            ConstantValue::F32(v) => format!("{}f", v),
            ConstantValue::F64(v) => format!("{}", v),
            ConstantValue::Null => "nullptr".to_string(),
            ConstantValue::Array(elems) => {
                let elems_str: Vec<String> = elems.iter().map(|e| self.lower_constant(e)).collect();
                format!("{{{}}}", elems_str.join(", "))
            }
            ConstantValue::Struct(fields) => {
                let fields_str: Vec<String> =
                    fields.iter().map(|f| self.lower_constant(f)).collect();
                format!("{{{}}}", fields_str.join(", "))
            }
        }
    }

    fn lower_binary_op(&self, op: &BinaryOp, lhs: &str, rhs: &str) -> String {
        match op {
            BinaryOp::Add => format!("{} + {}", lhs, rhs),
            BinaryOp::Sub => format!("{} - {}", lhs, rhs),
            BinaryOp::Mul => format!("{} * {}", lhs, rhs),
            BinaryOp::Div => format!("{} / {}", lhs, rhs),
            BinaryOp::Rem => format!("{} % {}", lhs, rhs),
            BinaryOp::And => format!("{} & {}", lhs, rhs),
            BinaryOp::Or => format!("{} | {}", lhs, rhs),
            BinaryOp::Xor => format!("{} ^ {}", lhs, rhs),
            BinaryOp::Shl => format!("{} << {}", lhs, rhs),
            BinaryOp::Shr => format!("{} >> {}", lhs, rhs),
            BinaryOp::Sar => format!("{} >> {}", lhs, rhs), // C handles sign extension
            BinaryOp::Fma => format!("fma({}, {}, 0.0f)", lhs, rhs), // Would need third arg
            BinaryOp::Pow => format!("pow({}, {})", lhs, rhs),
            BinaryOp::Min => format!("min({}, {})", lhs, rhs),
            BinaryOp::Max => format!("max({}, {})", lhs, rhs),
        }
    }

    fn lower_unary_op(&self, op: &UnaryOp, val: &str) -> String {
        match op {
            UnaryOp::Neg => format!("-{}", val),
            UnaryOp::Not => format!("~{}", val),
            UnaryOp::LogicalNot => format!("!{}", val),
            UnaryOp::Abs => format!("abs({})", val),
            UnaryOp::Sqrt => format!("sqrt({})", val),
            UnaryOp::Rsqrt => format!("rsqrt({})", val),
            UnaryOp::Floor => format!("floor({})", val),
            UnaryOp::Ceil => format!("ceil({})", val),
            UnaryOp::Round => format!("round({})", val),
            UnaryOp::Trunc => format!("trunc({})", val),
            UnaryOp::Sign => format!("copysign(1.0f, {})", val),
        }
    }

    fn lower_compare_op(&self, op: &CompareOp) -> &'static str {
        match op {
            CompareOp::Eq => "==",
            CompareOp::Ne => "!=",
            CompareOp::Lt => "<",
            CompareOp::Le => "<=",
            CompareOp::Gt => ">",
            CompareOp::Ge => ">=",
        }
    }

    fn lower_dimension(&self, dim: &Dimension, prefix: &str) -> String {
        match dim {
            Dimension::X => format!("{}.x", prefix),
            Dimension::Y => format!("{}.y", prefix),
            Dimension::Z => format!("{}.z", prefix),
        }
    }

    fn lower_math_op(&self, op: &MathOp) -> &'static str {
        match op {
            MathOp::Sin => "sin",
            MathOp::Cos => "cos",
            MathOp::Tan => "tan",
            MathOp::Asin => "asin",
            MathOp::Acos => "acos",
            MathOp::Atan => "atan",
            MathOp::Atan2 => "atan2",
            MathOp::Sinh => "sinh",
            MathOp::Cosh => "cosh",
            MathOp::Tanh => "tanh",
            MathOp::Exp => "exp",
            MathOp::Exp2 => "exp2",
            MathOp::Log => "log",
            MathOp::Log2 => "log2",
            MathOp::Log10 => "log10",
            MathOp::Lerp => "lerp",
            MathOp::Clamp => "clamp",
            MathOp::Step => "step",
            MathOp::SmoothStep => "smoothstep",
            MathOp::Fract => "fract",
            MathOp::CopySign => "copysign",
        }
    }

    fn get_value_name(&self, id: ValueId) -> String {
        self.value_names
            .get(&id)
            .cloned()
            .unwrap_or_else(|| format!("v{}", id.raw()))
    }

    fn get_or_create_name(&mut self, id: ValueId) -> String {
        if let Some(name) = self.value_names.get(&id) {
            return name.clone();
        }
        let name = format!("t{}", self.name_counter);
        self.name_counter += 1;
        self.value_names.insert(id, name.clone());
        name
    }

    fn emit_line(&mut self, line: &str) {
        let indent = "    ".repeat(self.indent);
        writeln!(self.output, "{}{}", indent, line).unwrap();
    }
}

/// Lowering errors.
#[derive(Debug, Clone)]
pub enum LoweringError {
    /// Unsupported capability.
    UnsupportedCapability(String),
    /// Undefined block reference.
    UndefinedBlock(BlockId),
    /// Undefined value reference.
    UndefinedValue(ValueId),
    /// Requires cooperative groups.
    RequiresCooperativeGroups,
    /// Type error.
    TypeError(String),
}

impl std::fmt::Display for LoweringError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            LoweringError::UnsupportedCapability(cap) => {
                write!(f, "Unsupported capability: {}", cap)
            }
            LoweringError::UndefinedBlock(id) => write!(f, "Undefined block: {}", id),
            LoweringError::UndefinedValue(id) => write!(f, "Undefined value: {}", id),
            LoweringError::RequiresCooperativeGroups => {
                write!(f, "Operation requires cooperative groups")
            }
            LoweringError::TypeError(msg) => write!(f, "Type error: {}", msg),
        }
    }
}

impl std::error::Error for LoweringError {}

/// Convenience function to lower IR to CUDA.
pub fn lower_to_cuda(module: &IrModule) -> Result<String, LoweringError> {
    CudaLowering::new(CudaLoweringConfig::default()).lower(module)
}

/// Lower IR to CUDA with custom config.
pub fn lower_to_cuda_with_config(
    module: &IrModule,
    config: CudaLoweringConfig,
) -> Result<String, LoweringError> {
    CudaLowering::new(config).lower(module)
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::IrBuilder;

    #[test]
    fn test_lower_simple_kernel() {
        let mut builder = IrBuilder::new("add_one");

        let x = builder.parameter("x", IrType::ptr(IrType::F32));
        let n = builder.parameter("n", IrType::I32);

        let idx = builder.global_thread_id(Dimension::X);
        let in_bounds = builder.lt(idx, n);

        let then_block = builder.create_block("body");
        let end_block = builder.create_block("end");

        builder.cond_branch(in_bounds, then_block, end_block);

        builder.switch_to_block(then_block);
        let one = builder.const_f32(1.0);
        let ptr = builder.gep(x, vec![idx]);
        let val = builder.load(ptr);
        let result = builder.add(val, one);
        builder.store(ptr, result);
        builder.branch(end_block);

        builder.switch_to_block(end_block);
        builder.ret();

        let module = builder.build();
        let cuda = lower_to_cuda(&module).unwrap();

        assert!(cuda.contains("__global__ void add_one"));
        assert!(cuda.contains("float* x"));
        assert!(cuda.contains("int32_t n"));
        assert!(cuda.contains("blockIdx.x * blockDim.x + threadIdx.x"));
    }

    #[test]
    fn test_lower_with_shared_memory() {
        let mut builder = IrBuilder::new("reduce");

        let _x = builder.parameter("x", IrType::ptr(IrType::F32));

        let shared = builder.shared_alloc(IrType::F32, 256);
        let _ = shared;

        builder.barrier();
        builder.ret();

        let module = builder.build();
        let cuda = lower_to_cuda(&module).unwrap();

        assert!(cuda.contains("__shared__ float"));
        assert!(cuda.contains("__syncthreads()"));
    }

    #[test]
    fn test_lower_with_atomics() {
        let mut builder = IrBuilder::new("atomic_add");

        let counter = builder.parameter("counter", IrType::ptr(IrType::U32));

        let one = builder.const_u32(1);
        let _old = builder.atomic_add(counter, one);

        builder.ret();

        let module = builder.build();
        let cuda = lower_to_cuda(&module).unwrap();

        assert!(cuda.contains("atomicAdd"));
    }

    #[test]
    fn test_lower_with_cooperative_groups() {
        let mut builder = IrBuilder::new("grid_reduce");
        builder.grid_sync();
        builder.ret();

        let module = builder.build();

        // Without cooperative groups, should fail
        let result = lower_to_cuda(&module);
        assert!(result.is_err());

        // With cooperative groups, should succeed
        let config = CudaLoweringConfig::sm80();
        let cuda = lower_to_cuda_with_config(&module, config).unwrap();

        assert!(cuda.contains("cooperative_groups"));
        assert!(cuda.contains("grid.sync()"));
    }

    #[test]
    fn test_lower_binary_ops() {
        let mut builder = IrBuilder::new("math");

        let a = builder.const_f32(1.0);
        let b = builder.const_f32(2.0);

        let _sum = builder.add(a, b);
        let _diff = builder.sub(a, b);
        let _prod = builder.mul(a, b);
        let _quot = builder.div(a, b);
        let _min = builder.min(a, b);
        let _max = builder.max(a, b);

        builder.ret();

        let module = builder.build();
        let cuda = lower_to_cuda(&module).unwrap();

        assert!(cuda.contains("+"));
        assert!(cuda.contains("-"));
        assert!(cuda.contains("*"));
        assert!(cuda.contains("/"));
        assert!(cuda.contains("min("));
        assert!(cuda.contains("max("));
    }
}
