//! CUDA Backend for RingKernel
//!
//! This crate provides NVIDIA CUDA GPU support for RingKernel using cudarc.
//!
//! # Features
//!
//! - Persistent kernel execution (cooperative groups)
//! - Lock-free message queues in GPU global memory
//! - PTX compilation via NVRTC
//! - Multi-GPU support
//!
//! # Requirements
//!
//! - NVIDIA GPU with Compute Capability 7.0+
//! - CUDA Toolkit 11.0+
//! - Native Linux (persistent kernels) or WSL2 (event-driven fallback)
//!
//! # Example
//!
//! ```ignore
//! use ringkernel_cuda::CudaRuntime;
//!
//! #[tokio::main]
//! async fn main() -> Result<(), Box<dyn std::error::Error>> {
//!     let runtime = CudaRuntime::new().await?;
//!     let kernel = runtime.launch("vector_add", Default::default()).await?;
//!     kernel.activate().await?;
//!     Ok(())
//! }
//! ```

#![warn(missing_docs)]

#[cfg(feature = "cuda")]
mod device;
#[cfg(feature = "cuda")]
mod kernel;
#[cfg(feature = "cuda")]
mod memory;
#[cfg(feature = "cuda")]
mod runtime;

#[cfg(feature = "cuda")]
pub use device::CudaDevice;
#[cfg(feature = "cuda")]
pub use kernel::CudaKernel;
#[cfg(feature = "cuda")]
pub use memory::{CudaBuffer, CudaControlBlock, CudaMemoryPool, CudaMessageQueue};
#[cfg(feature = "cuda")]
pub use runtime::CudaRuntime;

/// Re-export memory module for advanced usage.
#[cfg(feature = "cuda")]
pub mod memory_exports {
    pub use super::memory::{CudaBuffer, CudaControlBlock, CudaMemoryPool, CudaMessageQueue};
}

// Placeholder implementations when CUDA is not available
#[cfg(not(feature = "cuda"))]
mod stub {
    use async_trait::async_trait;
    use ringkernel_core::error::{Result, RingKernelError};
    use ringkernel_core::runtime::{
        Backend, KernelHandle, KernelId, LaunchOptions, RingKernelRuntime, RuntimeMetrics,
    };

    /// Stub CUDA runtime when CUDA feature is disabled.
    pub struct CudaRuntime;

    impl CudaRuntime {
        /// Create fails when CUDA is not available.
        pub async fn new() -> Result<Self> {
            Err(RingKernelError::BackendUnavailable(
                "CUDA feature not enabled".to_string(),
            ))
        }
    }

    #[async_trait]
    impl RingKernelRuntime for CudaRuntime {
        fn backend(&self) -> Backend {
            Backend::Cuda
        }

        fn is_backend_available(&self, _backend: Backend) -> bool {
            false
        }

        async fn launch(&self, _kernel_id: &str, _options: LaunchOptions) -> Result<KernelHandle> {
            Err(RingKernelError::BackendUnavailable("CUDA".to_string()))
        }

        fn get_kernel(&self, _kernel_id: &KernelId) -> Option<KernelHandle> {
            None
        }

        fn list_kernels(&self) -> Vec<KernelId> {
            vec![]
        }

        fn metrics(&self) -> RuntimeMetrics {
            RuntimeMetrics::default()
        }

        async fn shutdown(&self) -> Result<()> {
            Ok(())
        }
    }
}

#[cfg(not(feature = "cuda"))]
pub use stub::CudaRuntime;

/// Check if CUDA is available at runtime.
pub fn is_cuda_available() -> bool {
    #[cfg(feature = "cuda")]
    {
        // Check for CUDA devices
        cudarc::driver::CudaDevice::count()
            .map(|c| c > 0)
            .unwrap_or(false)
    }
    #[cfg(not(feature = "cuda"))]
    {
        false
    }
}

/// Get CUDA device count.
pub fn cuda_device_count() -> usize {
    #[cfg(feature = "cuda")]
    {
        cudarc::driver::CudaDevice::count().unwrap_or(0) as usize
    }
    #[cfg(not(feature = "cuda"))]
    {
        0
    }
}

/// PTX kernel source template for persistent ring kernel.
pub const RING_KERNEL_PTX_TEMPLATE: &str = r#"
//
// RingKernel Persistent Kernel Template
// Generated by ringkernel-cuda
//

.version 7.0
.target sm_70
.address_size 64

// Control block structure (128 bytes)
.struct ControlBlock {
    .u32 is_active;
    .u32 should_terminate;
    .u32 has_terminated;
    .u32 _pad1;
    .u64 messages_processed;
    .u64 messages_in_flight;
    .u64 input_head;
    .u64 input_tail;
    .u64 output_head;
    .u64 output_tail;
    .u32 input_capacity;
    .u32 output_capacity;
    .u32 input_mask;
    .u32 output_mask;
    // HLC state
    .u64 hlc_physical;
    .u64 hlc_logical;
    // Error state
    .u32 last_error;
    .u32 error_count;
    .b8 _reserved[16];
}

// Kernel entry point
.visible .entry ring_kernel_main(
    .param .u64 control_block_ptr,
    .param .u64 input_queue_ptr,
    .param .u64 output_queue_ptr,
    .param .u64 shared_state_ptr
) {
    // Thread identification
    .reg .u32 %tid, %bid, %gtid;
    mov.u32 %tid, %tid.x;
    mov.u32 %bid, %ctaid.x;

    // Load control block pointer
    .reg .u64 %cb_ptr;
    ld.param.u64 %cb_ptr, [control_block_ptr];

    // Main processing loop (persistent kernel)
MAIN_LOOP:
    // Check termination flag
    .reg .u32 %should_term;
    ld.global.acquire.gpu.u32 %should_term, [%cb_ptr + 4];
    setp.ne.u32 %p1, %should_term, 0;
    @%p1 bra EXIT;

    // Check if active
    .reg .u32 %is_active;
    ld.global.acquire.gpu.u32 %is_active, [%cb_ptr];
    setp.eq.u32 %p2, %is_active, 0;
    @%p2 bra MAIN_LOOP;  // Spin if not active

    // Process messages (placeholder - actual kernel code inserted here)
    // USER_KERNEL_CODE

    // Continue loop
    bra MAIN_LOOP;

EXIT:
    // Mark as terminated
    .reg .u32 %one;
    mov.u32 %one, 1;
    st.global.release.gpu.u32 [%cb_ptr + 8], %one;
    ret;
}
"#;
