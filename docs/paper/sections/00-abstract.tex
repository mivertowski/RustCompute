% Abstract
% Target: 150-250 words summarizing the key contributions

The actor model, introduced by Hewitt in 1973, has become foundational for building
concurrent and distributed systems. However, existing implementations target CPU
architectures, leaving GPU parallelism largely unexplored for actor-based computation.
We present the \textbf{GPU-Native Persistent Actor Model}, a paradigm that treats GPU
compute units as long-running actors with lock-free message passing and causal ordering.

This paper describes \textbf{RingKernel}, the Rust implementation of this paradigm,
alongside three companion frameworks: \textbf{DotCompute} (.NET), \textbf{Orleans.GpuBridge}
(Microsoft Orleans integration), and \textbf{RustGraph} (living graph database). Together,
these systems demonstrate the broad applicability of GPU-native actors.

Our key contributions are: (1) formalization of GPU actor semantics with Host-to-Kernel (H2K),
Kernel-to-Host (K2H), and Kernel-to-Kernel (K2K) messaging channels; (2) a 128-byte
\texttt{ControlBlock} structure for GPU-resident actor lifecycle management; (3) integration
of Hybrid Logical Clocks (HLC) for causal ordering across thousands of concurrent GPU actors;
and (4) cross-language implementations proving the paradigm's universality.

We evaluate on NVIDIA RTX Ada GPUs, demonstrating that persistent GPU actors achieve
\textbf{11,327$\times$ lower latency} for interactive commands compared to traditional
kernel launches (0.03$\mu$s vs 317$\mu$s). For mixed workloads, GPU-native actors achieve
\textbf{2.7$\times$ higher throughput}, enabling new classes of interactive GPU applications
including real-time fraud detection, living graph analytics, and distributed digital twins.
